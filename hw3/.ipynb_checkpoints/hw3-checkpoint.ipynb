{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a457678-d904-4d83-9e4f-ef9de36fe848",
   "metadata": {},
   "source": [
    "# Homework 3\n",
    "### Name: William Martinez\n",
    "### Collaborators: None\n",
    "\n",
    "Due date: May 19, 2024\n",
    "\n",
    "Submission instructions: \n",
    "- __Autograder will not be used for scoring, but you still need to submit the python file converted from this notebook (.py) and the notebook file (.ipynb) to the code submission window.__ \n",
    "To convert a Jupyter Notebook (`.ipynb`) to a regular Python script (`.py`):\n",
    "  - In Jupyter Notebook: File > Download as > Python (.py)\n",
    "  - In JupyterLab: File > Save and Export Notebook As... > Executable Script\n",
    "  - In VS Code Jupyter Notebook App: In the toolbar, there is an Export menu. Click on it, and select Python script.\n",
    "- Submit `hw3.ipynb` and `hw3.py` on Gradescope under the window \"Homework 3 - code\". Do **NOT** change the file name.\n",
    "- Convert this notebook into a pdf file and submit it on Gradescope under the window \"Homework 3 - PDF\". Make sure all your code and text outputs in the problems are visible. \n",
    "\n",
    "\n",
    "This homework requires two new packages, `pyarrow` and `duckdb`. Pleas make sure to install them in your `BIOSTAT203C-24S` environment:\n",
    "\n",
    "```bash\n",
    "conda activate BIOSTAT203C-24S\n",
    "conda install -c conda-forge pyarrow python-duckdb\n",
    "```\n",
    "\n",
    "\n",
    "## Problem 1. \n",
    "\n",
    "Recall the simple random walk.  At each step, we flip a fair coin. If heads, we move \"foward\" one unit; if tails, we move \"backward.\" \n",
    "\n",
    "### (A).\n",
    "\n",
    "Way back in Homework 1, you wrote some code to simulate a random walk in Python. \n",
    "\n",
    "Start with this code, or use posted solutions for HW1. If you have since written random walk code that you prefer, you can use this instead. Regardless, take your code, modify it, and enclose it in a function `rw()`. This function should accept a single argument `n`, the length of the walk. The output should be a list giving the position of the random walker, starting with the position after the first step. For example, \n",
    "\n",
    "```python\n",
    "rw(5)\n",
    "[1, 2, 3, 2, 3]\n",
    "```\n",
    "\n",
    "Unlike in the HW1 problem, you should not use upper or lower bounds. The walk should always run for as long as the user-specified number of steps `n`. \n",
    "\n",
    "Use your function to print out the positions of a random walk of length `n = 10`. \n",
    "\n",
    "Don't forget a helpful docstring! \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b6401a3-a60d-46ca-8d4a-6603451ec7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f0e4a4f-fee7-4d02-ad4d-32c61b65b762",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, -1, 0, 1, 2, 3, 4, 5, 6, 5, 4]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def rw(n):\n",
    "    pos = 0\n",
    "    positions = []\n",
    "    while len(positions) <= n:\n",
    "      x = random.choice([\"heads\", \"tails\"])\n",
    "      if x == \"heads\":\n",
    "          pos += 1\n",
    "          positions.append(pos)\n",
    "      elif x == \"tails\":\n",
    "          pos -= 1\n",
    "          positions.append(pos)\n",
    "    return positions\n",
    "\n",
    "rw(10)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678abaa8-a334-47e1-81f6-590724c0a75f",
   "metadata": {},
   "source": [
    "### (B). \n",
    "\n",
    "Now create a function called `rw2(n)`, where the argument `n` means the same thing that it did in Part A. Do so using `numpy` tools. Demonstrate your function as above, by creating a random walk of length 10. You can (and should) return your walk as a `numpy` array. \n",
    "\n",
    "**Requirements**: \n",
    "\n",
    "- No for-loops. \n",
    "- This function is simple enough to be implemented as a one-liner of fewer than 80 characters, using lambda notation. Even if you choose not to use lambda notation, the body of your function definition should be no more than three lines long. Importing `numpy` does not count as a line. \n",
    "- A docstring is required if and only if you take more than one line to define the function. \n",
    "\n",
    "**Hints**:\n",
    "\n",
    "- Check the documentation for `np.random.choice()`. \n",
    "- `np.cumsum()`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a940cccd-ff22-492e-8957-b7cf0da5939f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1, -2, -3, -4, -3, -4, -5, -6, -5, -6])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rw2 = lambda n: np.random.choice([-1, 1], size=n, replace=True).cumsum()\n",
    "\n",
    "rw2(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad5c360-3302-4375-a151-ab3a63ec5fa3",
   "metadata": {},
   "source": [
    "### (C).\n",
    "\n",
    "Use the `%timeit` magic macro to compare the runtime of `rw()` and `rw2()`. Test how each function does in computing a random walk of length `n = 10000`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e097a85-c7ba-415b-b31f-d153ec3ef667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "362 µs ± 338 ns per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "rw(10_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24524a29-f01b-4491-b776-525626deca0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61.1 µs ± 226 ns per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "rw2(10_000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fbea2f6-1e39-415a-aa16-defe9ba79268",
   "metadata": {},
   "source": [
    "### (D). \n",
    "\n",
    "Write a few sentences in which you comment on (a) the performance of each function and (b) the ease of writing and reading each function. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6d1d1a-efa5-41db-bc3f-bcc2f86be13b",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "The function, `rw2()`, was 82% faster than the fuction, `rw()`. Built-in python list operations were used in `rw()` and numpy array operations were used in `rw2()`. The average run-times for `rw()` and `rw2()` were 61.1 µs and 362 µs, respectively. The numpy array operations in `rw2()` were easier to write, occupying only one line, and was more readable than the built-in python list operations in `rw()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85b5fcb-9c45-4a16-8642-1e47216ccbc4",
   "metadata": {},
   "source": [
    "### (E). \n",
    "\n",
    "\n",
    "In this problem, we will perform a `d`-dimensional random walk. There are many ways to define such a walk. Here's the definition we'll use for this problem: \n",
    "\n",
    "> At each timestep, the walker takes one random step forward or backward **in each of `d` directions.** \n",
    "\n",
    "For example, in a two-dimensional walk on a grid, in each timestep the walker would take a step either north or south, and then another step either east or west. Another way to think about is as the walker taking a single \"diagonal\" step either northeast, southeast, southwest, or northwest. \n",
    "\n",
    "Write a function called `rw_d(n,d)` that implements a `d`-dimensional random walk. `n` is again the number of steps that the walker should take, and `d` is the dimension of the walk. The output should be given as a `numpy` array of shape `(n,d)`, where the `k`th row of the array specifies the position of the walker after `k` steps. For example: \n",
    "\n",
    "```python\n",
    "P = rw_d(5, 3)\n",
    "P\n",
    "```\n",
    "```\n",
    "array([[-1, -1, -1],\n",
    "       [ 0, -2, -2],\n",
    "       [-1, -3, -3],\n",
    "       [-2, -2, -2],\n",
    "       [-1, -3, -1]])\n",
    "```\n",
    "\n",
    "In this example, the third row `P[2,:] = [-1, -3, -3]` gives the position of the walk after 3 steps. \n",
    "\n",
    "Demonstrate your function by generating a 3d walk with 5 steps, as shown in the example above. \n",
    "\n",
    "All the same requirements and hints from Part B apply in this problem as well. It should be possible to solve this problem by making only a few small modifications to your solution from Part B. If you are finding that this is not possible, you may want to either (a) read the documentation for the relevant `numpy` functions more closely or (b) reconsider your Part B approach. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0d762975-6f8a-4235-b4a7-3a16eb0b05e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1,  1, -1],\n",
       "       [ 0,  0, -2],\n",
       "       [-1,  1, -1],\n",
       "       [-2,  0,  0],\n",
       "       [-3,  1, -1]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def rw_d(n, d):\n",
    "  positions = (np.random.choice([-1, 1], size = (n * d), replace = True)\n",
    "    .reshape(n, d)\n",
    "    .cumsum(axis=0)\n",
    "  )\n",
    "  return positions\n",
    "  \n",
    "\n",
    "rw_d(5, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b383552-1ec5-4bd1-9c7b-b67dc7fe67cb",
   "metadata": {},
   "source": [
    "### (F).\n",
    "\n",
    "In a few sentences, describe how you would have solved Part E without `numpy` tools. Take a guess as to how many lines it would have taken you to define the appropriate function. Based on your findings in Parts C and D, how would you expect its performance to compare to your `numpy`-based function from Part E? Which approach would your recommend? \n",
    "\n",
    "Note: while I obviously prefer the `numpy` approach, it is reasonable and valid to prefer the \"vanilla\" way instead. Either way, you should be ready to justify your preference on the basis of writeability, readability, and performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b63ced-cb79-4aed-8321-c68722237e94",
   "metadata": {},
   "source": [
    "**ANSWER:** Without using numpy tools, Part E could be solved by using a for-loop and performing the `rw2()` function d times with an input of n; this would be followed by using transform and concatening the \n",
    "\n",
    "The total number of steps is the number of steps in each direction multiplied by the number of directions/dimentions. The former function, `rw2()`, was used to generate positionsThe numpy modifier, `.reshape()`, was "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b307e8e5-1278-4bba-b22f-bf7816eb43c8",
   "metadata": {},
   "source": [
    "### (G).\n",
    "\n",
    "Once you've implemented `rw_d()`, you can run the following code to generate a large random walk and visualize it. \n",
    "\n",
    "```python\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "W = rw_d(20000, 2)\n",
    "plt.plot(W[:,0], W[:,1])\n",
    "```\n",
    "\n",
    "You may be interested in looking at several other visualizations of multidimensional random walks [on Wikipedia](https://en.wikipedia.org/wiki/Random_walk). Your result in this part will not look exactly the same, but should look qualitatively fairly similar. \n",
    "\n",
    "You only need to show one plot. If you like, you might enjoy playing around with the plot settings. While `ax.plot()` is the normal method to use here, `ax.scatter()` with partially transparent points can also produce some intriguing images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da1d9e7-9625-445d-b3c9-a9957d2b435c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "def78985-0fc4-4ac7-a804-4debe01426b4",
   "metadata": {},
   "source": [
    "## Problem 2. Reading MIMIC-IV datafile\n",
    "In this exercise, we explore various tools for ingesting the [MIMIC-IV](https://mimic.mit.edu/docs/iv/) data introduced in BIOSTAT 203B, but we will do it in Python this time.\n",
    "\n",
    "Let's display the contents of MIMIC `hosp` and `icu` data folders: (if a cell starts with a `!`, the command is run in the shell.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1948eaab-6f54-482a-a0ca-b1fa36a38f4c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 8903696\n",
      "-rw-r--r--  1 kose  staff    15516088 Jan  5  2023 admissions.csv.gz\n",
      "-rw-r--r--  1 kose  staff      427468 Jan  5  2023 d_hcpcs.csv.gz\n",
      "-rw-r--r--  1 kose  staff      859438 Jan  5  2023 d_icd_diagnoses.csv.gz\n",
      "-rw-r--r--  1 kose  staff      578517 Jan  5  2023 d_icd_procedures.csv.gz\n",
      "-rw-r--r--  1 kose  staff       12900 Jan  5  2023 d_labitems.csv.gz\n",
      "-rw-r--r--  1 kose  staff    25070720 Jan  5  2023 diagnoses_icd.csv.gz\n",
      "-rw-r--r--  1 kose  staff     7426955 Jan  5  2023 drgcodes.csv.gz\n",
      "-rw-r--r--  1 kose  staff   508524623 Jan  5  2023 emar.csv.gz\n",
      "-rw-r--r--  1 kose  staff   471096030 Jan  5  2023 emar_detail.csv.gz\n",
      "-rw-r--r--  1 kose  staff     1767138 Jan  5  2023 hcpcsevents.csv.gz\n",
      "-rw-r--r--  1 kose  staff        2907 May  2 11:03 index.html\n",
      "-rw-r--r--@ 1 kose  staff  1939088924 May  3 14:10 labevents.csv.gz\n",
      "-rw-r--r--  1 kose  staff    96698496 Jan  5  2023 microbiologyevents.csv.gz\n",
      "-rw-r--r--  1 kose  staff    36124944 Jan  5  2023 omr.csv.gz\n",
      "-rw-r--r--  1 kose  staff     2312631 Jan  5  2023 patients.csv.gz\n",
      "-rw-r--r--  1 kose  staff   398753125 Jan  5  2023 pharmacy.csv.gz\n",
      "-rw-r--r--  1 kose  staff   498505135 Jan  5  2023 poe.csv.gz\n",
      "-rw-r--r--  1 kose  staff    25477219 Jan  5  2023 poe_detail.csv.gz\n",
      "-rw-r--r--  1 kose  staff   458817415 Jan  5  2023 prescriptions.csv.gz\n",
      "-rw-r--r--  1 kose  staff     6027067 Jan  5  2023 procedures_icd.csv.gz\n",
      "-rw-r--r--  1 kose  staff      122507 Jan  5  2023 provider.csv.gz\n",
      "-rw-r--r--  1 kose  staff     6781247 Jan  5  2023 services.csv.gz\n",
      "-rw-r--r--  1 kose  staff    36158338 Jan  5  2023 transfers.csv.gz\n"
     ]
    }
   ],
   "source": [
    "!ls -l physionet.org/files/mimiciv/2.2/hosp/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "512dcc57-1024-4e42-a2f5-c028ee351d82",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 6155976\n",
      "-rw-r--r--  1 kose  staff       35893 Jan  5  2023 caregiver.csv.gz\n",
      "-rw-r--r--  1 kose  staff  2467761053 Jan  5  2023 chartevents.csv.gz\n",
      "-rw-r--r--  1 kose  staff       57476 Jan  5  2023 d_items.csv.gz\n",
      "-rw-r--r--  1 kose  staff    45721062 Jan  5  2023 datetimeevents.csv.gz\n",
      "-rw-r--r--  1 kose  staff     2614571 Jan  5  2023 icustays.csv.gz\n",
      "-rw-r--r--  1 kose  staff        1336 May  2 11:03 index.html\n",
      "-rw-r--r--  1 kose  staff   251962313 Jan  5  2023 ingredientevents.csv.gz\n",
      "-rw-r--r--  1 kose  staff   324218488 Jan  5  2023 inputevents.csv.gz\n",
      "-rw-r--r--  1 kose  staff    38747895 Jan  5  2023 outputevents.csv.gz\n",
      "-rw-r--r--  1 kose  staff    20717852 Jan  5  2023 procedureevents.csv.gz\n"
     ]
    }
   ],
   "source": [
    "!ls -l physionet.org/files/mimiciv/2.2/icu/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b9d704-df48-4dc8-a3d2-35747b75f2f8",
   "metadata": {},
   "source": [
    "### (A). Speed, memory, and data types\n",
    "\n",
    "Standard way to read a CSV file would be using the `read_csv` function of the `pandas` package. Let us check the speed of reading a moderate-sized compressed csv file, `admissions.csv.gz`. How much memory does the resulting data frame use?\n",
    "\n",
    "_Note:_ If you start a cell with `%%time`, the runtime will be measured. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73258362-fb47-405c-80a4-a7d79e73409c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5 µs, sys: 2 µs, total: 7 µs\n",
      "Wall time: 11.2 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab09d40-a407-4c5d-b660-a4e2fd7ec4c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e1491db4-c6ea-4ad1-8071-42c129cb08c3",
   "metadata": {},
   "source": [
    "### (B). User-supplied data types\n",
    "\n",
    "Re-ingest `admissions.csv.gz` by indicating appropriate column data types in [`pd.read_csv`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html). Does the run time change? How much memory does the result dataframe use? (Hint: `dtype` and `parse_dates` arguments in `pd.read_csv`.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8a6a2e-8b82-4612-84b7-f45370094b97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d56d7ab0-adfb-406c-a009-86065a7f4ba1",
   "metadata": {},
   "source": [
    "## Problem 3. Ingest big data files\n",
    "\n",
    "\n",
    "Let us focus on a bigger file, `labevents.csv.gz`, which is about 125x bigger than `admissions.csv.gz`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "edfd22f7-e1a5-4f5a-aca5-04ce598569f2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r--@ 1 kose  staff  1939088924 May  3 14:10 physionet.org/files/mimiciv/2.2/hosp/labevents.csv.gz\n"
     ]
    }
   ],
   "source": [
    "!ls -l physionet.org/files/mimiciv/2.2/hosp/labevents.csv.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a01b57-8d97-4107-aa33-8b64aa97b048",
   "metadata": {},
   "source": [
    "Display the first 10 lines of this file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3b0364a-21d8-434f-9bba-5b35cbd47c15",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labevent_id,subject_id,hadm_id,specimen_id,itemid,order_provider_id,charttime,storetime,value,valuenum,valueuom,ref_range_lower,ref_range_upper,flag,priority,comments\n",
      "1,10000032,,45421181,51237,P28Z0X,2180-03-23 11:51:00,2180-03-23 15:15:00,1.4,1.4,,0.9,1.1,abnormal,ROUTINE,\n",
      "2,10000032,,45421181,51274,P28Z0X,2180-03-23 11:51:00,2180-03-23 15:15:00,___,15.1,sec,9.4,12.5,abnormal,ROUTINE,VERIFIED.\n",
      "3,10000032,,52958335,50853,P28Z0X,2180-03-23 11:51:00,2180-03-25 11:06:00,___,15,ng/mL,30,60,abnormal,ROUTINE,NEW ASSAY IN USE ___: DETECTS D2 AND D3 25-OH ACCURATELY.\n",
      "4,10000032,,52958335,50861,P28Z0X,2180-03-23 11:51:00,2180-03-23 16:40:00,102,102,IU/L,0,40,abnormal,ROUTINE,\n",
      "5,10000032,,52958335,50862,P28Z0X,2180-03-23 11:51:00,2180-03-23 16:40:00,3.3,3.3,g/dL,3.5,5.2,abnormal,ROUTINE,\n",
      "6,10000032,,52958335,50863,P28Z0X,2180-03-23 11:51:00,2180-03-23 16:40:00,109,109,IU/L,35,105,abnormal,ROUTINE,\n",
      "7,10000032,,52958335,50864,P28Z0X,2180-03-23 11:51:00,2180-03-23 16:40:00,___,8,ng/mL,0,8.7,,ROUTINE,MEASURED BY ___.\n",
      "8,10000032,,52958335,50868,P28Z0X,2180-03-23 11:51:00,2180-03-23 16:40:00,12,12,mEq/L,8,20,,ROUTINE,\n",
      "9,10000032,,52958335,50878,P28Z0X,2180-03-23 11:51:00,2180-03-23 16:40:00,143,143,IU/L,0,40,abnormal,ROUTINE,\n",
      "zcat: error writing to output: Broken pipe\n"
     ]
    }
   ],
   "source": [
    "!zcat < physionet.org/files/mimiciv/2.2/hosp/labevents.csv.gz | head -10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58352877-c834-4488-8ea3-7360c347a754",
   "metadata": {},
   "source": [
    "### (A). Ingest `labevents.csv.gz` by `pd.read_csv`\n",
    "\n",
    "Try to ingest `labevents.csv.gz` using `pd.read_csv`. What happens? If it takes more than 5 minutes on your computer, then abort the program and report your findings. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9088997-7a48-4b0b-b331-afab3e837925",
   "metadata": {},
   "source": [
    "### (B). Ingest selected columns of `labevents.csv.gz` by `pd.read_csv`\n",
    "\n",
    "Try to ingest only columns `subject_id`, `itemid`, `charttime`, and `valuenum` in `labevents.csv.gz` using `pd.read_csv`.  Does this solve the ingestion issue? (Hint: `usecols` argument in `pd.read_csv`.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5c3479-c29f-4f4a-be2e-1cdad8bcb622",
   "metadata": {},
   "source": [
    "### (C). Ingest subset of `labevents.csv.gz`\n",
    "\n",
    "Back in BIOSTAT 203B, our first strategy to handle this big data file was to make a subset of the `labevents` data.  Read the [MIMIC documentation](https://mimic.mit.edu/docs/iv/modules/hosp/labevents/) for the content in data file `labevents.csv.gz`.\n",
    "\n",
    "As before, we will only be interested in the following lab items: creatinine (50912), potassium (50971), sodium (50983), chloride (50902), bicarbonate (50882), hematocrit (51221), white blood cell count (51301), and glucose (50931) and the following columns: `subject_id`, `itemid`, `charttime`, `valuenum`. \n",
    "\n",
    "Rerun the Bash command to extract these columns and rows from `labevents.csv.gz` and save the result to a new file `labevents_filtered.csv.gz` in the current working directory (Q2.3 of HW2). How long does it take?\n",
    "\n",
    "Display the first 10 lines of the new file `labevents_filtered.csv.gz`. How many lines are in this new file? How long does it take `pd.read_csv()` to ingest `labevents_filtered.csv.gz`?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e712a136-6b0d-46ab-8987-50ca1c04e49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1abb6a53-7c9a-4adb-baea-bda420e5d690",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "35433429-4df8-4d6f-adbf-93dbb35b7ac2",
   "metadata": {},
   "source": [
    "### (D). Review\n",
    "\n",
    "Write several sentences on what Apache Arrow, the Parquet format, and DuckDB are. Imagine you want to explain it to a layman in an elevator, as you did before. (It's OK to copy-paste the sentences from your previous submission.)\n",
    "\n",
    "Also, now is the good time to review [basic SQL commands](https://ucla-biostat-203b.github.io/2024winter/slides/12-dbplyr/dbintro.html) covered in BIOSTAT 203B."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff21425-0099-419e-9ff1-575719c54050",
   "metadata": {},
   "source": [
    "### (E). Ingest `labevents.csv.gz` by Apache Arrow\n",
    "\n",
    "Our second strategy again is to use [Apache Arrow](https://arrow.apache.org/) for larger-than-memory data analytics. We will use the package `pyarrow`. Unlike in R, this package works with the `csv.gz` format. We don't need to decompress the data. We could just use `dplyr` verbs in R, but here, we need a different set of commands. The core idea behind the commands are still the same, though.\n",
    "\n",
    "- Let's use [`pyarrow.csv.read_csv`](https://arrow.apache.org/docs/python/generated/pyarrow.csv.read_csv.html) to ingest `labevents.csv.gz`. It creates an object of type [`pyarrow.Table`](https://arrow.apache.org/docs/python/generated/pyarrow.Table.html).\n",
    "\n",
    "- Next, select columns using the [`select()`](https://arrow.apache.org/docs/python/generated/pyarrow.Table.html#pyarrow.Table.select) method. \n",
    "\n",
    "- As in (C), filter the rows based on the column `itemid` using the [`filter()`](https://arrow.apache.org/docs/python/generated/pyarrow.Table.html#pyarrow.Table.filter) method. It is strongly recommended to use [`Expression`](https://arrow.apache.org/docs/python/generated/pyarrow.dataset.Expression), in particular, the `isin()` method. \n",
    "\n",
    "- Finally, let's obtain the result in `pandas` `DataFrame` using the method `to_pandas()`. \n",
    "\n",
    "How long does the ingest+select+filter process take? Display the number of rows and the first 10 rows of the result dataframe, and make sure they match those of (C)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3349e873-3c30-4650-96bc-02ef9b13dbe1",
   "metadata": {},
   "source": [
    "### (F). Compress `labevents.csv.gz` to Parquet format and ingest/select/filter\n",
    "\n",
    "\n",
    "Re-write the csv.gz file `labevents.csv.gz` in the binary Parquet format (Hint: [`pyarrow.parquet.write_table`](https://arrow.apache.org/docs/python/generated/pyarrow.parquet.write_table.html).) How large is the Parquet file(s)? \n",
    "\n",
    "How long does the ingest+select+filter process of the Parquet file(s) take?  \n",
    "Display the number of rows and the first 10 rows of the result dataframe and make sure they match those in (C). \n",
    "\n",
    "__This should be significantly faster than all the previous results.__ \n",
    "_Hint._ Use [`pyarrow.parquet.read_table`](https://arrow.apache.org/docs/python/generated/pyarrow.parquet.read_table.html) method with the keyword argument `columns`. Also, make sure that you are using an `Expression`. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d97b623-6c1d-4db4-a604-ec35841dbc8e",
   "metadata": {},
   "source": [
    "### (G). DuckDB\n",
    "\n",
    "Let's use `duckdb` package in Python to use the DuckDB interface. In Python, DuckDB can interact smoothly with `pandas` and `pyarrow`. I recommend reading: \n",
    "\n",
    "- https://duckdb.org/2021/05/14/sql-on-pandas.html\n",
    "- https://duckdb.org/docs/guides/python/sql_on_arrow.html\n",
    "\n",
    "In Python, you will mostly use SQL commands to work with DuckDB. Check out the [data ingestion API](https://duckdb.org/docs/api/python/data_ingestion).\n",
    "\n",
    "\n",
    "Ingest the Parquet file, select columns, and filter rows as in (F). How long does the ingest+select+filter process take? Please make sure to call `.df()` method to have the final result as a `pandas` `DataFrame`. Display the number of rows and the first 10 rows of the result dataframe and make sure they match those in (C). \n",
    "\n",
    "__This should be significantly faster than the results before (but not including) Part (F).__ \n",
    "_Hint_: It could be a single SQL command.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02da79d3-c8ec-4785-a9c3-3a5fc63de358",
   "metadata": {},
   "source": [
    "## Problem 4. Ingest and filter `chartevents.csv.gz`\n",
    "\n",
    "[`chartevents.csv.gz`](https://mimic.mit.edu/docs/iv/modules/icu/chartevents/) contains all the charted data available for a patient. During their ICU stay, the primary repository of a patient’s information is their electronic chart. The `itemid` variable indicates a single measurement type in the database. The `value` variable is the value measured for `itemid`. The first 10 lines of `chartevents.csv.gz` are\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69d1f3a0-6342-42f9-9902-44030612c6d1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject_id,hadm_id,stay_id,caregiver_id,charttime,storetime,itemid,value,valuenum,valueuom,warning\n",
      "10000032,29079034,39553978,47007,2180-07-23 21:01:00,2180-07-23 22:15:00,220179,82,82,mmHg,0\n",
      "10000032,29079034,39553978,47007,2180-07-23 21:01:00,2180-07-23 22:15:00,220180,59,59,mmHg,0\n",
      "10000032,29079034,39553978,47007,2180-07-23 21:01:00,2180-07-23 22:15:00,220181,63,63,mmHg,0\n",
      "10000032,29079034,39553978,47007,2180-07-23 22:00:00,2180-07-23 22:15:00,220045,94,94,bpm,0\n",
      "10000032,29079034,39553978,47007,2180-07-23 22:00:00,2180-07-23 22:15:00,220179,85,85,mmHg,0\n",
      "10000032,29079034,39553978,47007,2180-07-23 22:00:00,2180-07-23 22:15:00,220180,55,55,mmHg,0\n",
      "10000032,29079034,39553978,47007,2180-07-23 22:00:00,2180-07-23 22:15:00,220181,62,62,mmHg,0\n",
      "10000032,29079034,39553978,47007,2180-07-23 22:00:00,2180-07-23 22:15:00,220210,20,20,insp/min,0\n",
      "10000032,29079034,39553978,47007,2180-07-23 22:00:00,2180-07-23 22:15:00,220277,95,95,%,0\n",
      "zcat: error writing to output: Broken pipe\n"
     ]
    }
   ],
   "source": [
    "!zcat < physionet.org/files/mimiciv/2.2/icu/chartevents.csv.gz | head -10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503e290e-44cf-4ac8-9060-43d96bef0160",
   "metadata": {},
   "source": [
    "[`d_items.csv.gz`](https://mimic.mit.edu/docs/iv/modules/icu/d_items/) is the dictionary for the `itemid` in `chartevents.csv.gz`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1bd8d66-0961-4f95-9f02-f576fb7a07c0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "itemid,label,abbreviation,linksto,category,unitname,param_type,lownormalvalue,highnormalvalue\n",
      "220001,Problem List,Problem List,chartevents,General,,Text,,\n",
      "220003,ICU Admission date,ICU Admission date,datetimeevents,ADT,,Date and time,,\n",
      "220045,Heart Rate,HR,chartevents,Routine Vital Signs,bpm,Numeric,,\n",
      "220046,Heart rate Alarm - High,HR Alarm - High,chartevents,Alarms,bpm,Numeric,,\n",
      "220047,Heart Rate Alarm - Low,HR Alarm - Low,chartevents,Alarms,bpm,Numeric,,\n",
      "220048,Heart Rhythm,Heart Rhythm,chartevents,Routine Vital Signs,,Text,,\n",
      "220050,Arterial Blood Pressure systolic,ABPs,chartevents,Routine Vital Signs,mmHg,Numeric,90,140\n",
      "220051,Arterial Blood Pressure diastolic,ABPd,chartevents,Routine Vital Signs,mmHg,Numeric,60,90\n",
      "220052,Arterial Blood Pressure mean,ABPm,chartevents,Routine Vital Signs,mmHg,Numeric,,\n",
      "zcat: error writing to output: Broken pipe\n"
     ]
    }
   ],
   "source": [
    "!zcat < physionet.org/files/mimiciv/2.2/icu/d_items.csv.gz | head -10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f757e5-9637-4549-b746-1aefce427a75",
   "metadata": {},
   "source": [
    "Again, we are interested in the vitals for ICU patients: heart rate (220045), mean non-invasive blood pressure (220181), systolic non-invasive blood pressure (220179), body temperature in Fahrenheit (223761), and respiratory rate (220210). Retrieve a subset of `chartevents.csv.gz` only containing these items, using the favorite method you learnt in Problem 3. \n",
    "\n",
    "Document the steps and show your code. Display the number of rows and the first 10 rows of the result `DataFrame`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "203C",
   "language": "python",
   "name": "203c"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
