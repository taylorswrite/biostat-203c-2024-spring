{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a5ec0ce-a3ed-4d8c-ba9b-eda7d7ac5ba2",
   "metadata": {},
   "source": [
    "# Homework 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483292de-c8df-47fd-97a3-ac44957f53f7",
   "metadata": {},
   "source": [
    "Due date: May 26, 2024\n",
    "\n",
    "### Submission instructions: \n",
    "- __Autograder will not be used for scoring, but you still need to submit the python file converted from this notebook (.py) and the notebook file (.ipynb) to the code submission window.__ \n",
    "To convert a Jupyter Notebook (`.ipynb`) to a regular Python script (`.py`):\n",
    "  - In Jupyter Notebook: File > Download as > Python (.py)\n",
    "  - In JupyterLab: File > Save and Export Notebook As... > Executable Script\n",
    "  - In VS Code Jupyter Notebook App: In the toolbar, there is an Export menu. Click on it, and select Python script.\n",
    "- Submit `hw4.ipynb` and `hw4.py` on Gradescope under the window \"Homework 4 - code\". Do **NOT** change the file name.\n",
    "- Convert this notebook into a pdf file and submit it on Gradescope under the window \"Homework 4 - PDF\". Make sure all your code and text outputs in the problems are visible. \n",
    "\n",
    "\n",
    "### General instructions: \n",
    "\n",
    "In this homework, we will use pandas to build a cohort of ICU stays and visualize the results from the MIMIC-IV dataset, which you did for Homework 3 in BIOSTAT 203B. \n",
    "\n",
    "For processing the Parquet files, one other option is [`polars`](https://pola.rs/). The package is designed for rapid analysis of data frames, possibly larger than memory, with pandas-like syntax, Apache Arrow-based data representation and the Rust language as its backend. Syntax is similar to what you have used for `pyarrow`. You are allowed to use any method you like for analyzing data, but use of `pyarrow`, `duckdb`, or `polars` is certainly recommended for larger files to save your memory and time. (_Hint_: If you want to try `polars`, look into `scan_parquet()` and `LazyFrame`. The package `polars` supports lazy evaluation similar to what you have seen in the R `arrow` package.)\n",
    "\n",
    "For visualization, you may use packages `matplotlib`, `seaborn`, and/or `plotly`. The use of `plotnine` is not allowed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64a3d0c-a13d-41df-b140-7494951b94e2",
   "metadata": {},
   "source": [
    "Please run the code below to show your system information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6176177f-b7b8-4a86-9ec7-67f1ebf5905a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import platform\n",
    "\n",
    "import psutil\n",
    "\n",
    "\n",
    "def get_system_info():\n",
    "    try:\n",
    "        info = {}\n",
    "        info[\"platform\"] = platform.system()\n",
    "        info[\"platform-release\"] = platform.release()\n",
    "        info[\"platform-version\"] = platform.version()\n",
    "        info[\"architecture\"] = platform.machine()\n",
    "        info[\"processor\"] = platform.processor()\n",
    "        info[\"ram\"] = str(round(psutil.virtual_memory().total / (1024.0**3))) + \" GB\"\n",
    "        for k, v in info.items():\n",
    "            print(f\"{k}:\\t{v}\")\n",
    "    except Exception as e:\n",
    "        logging.exception(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1dd86c1f-0eca-4589-876b-59feea048f1a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "platform:\tLinux\n",
      "platform-release:\t6.5.0-28-generic\n",
      "platform-version:\t#29~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Apr  4 14:39:20 UTC 2\n",
      "architecture:\tx86_64\n",
      "processor:\tx86_64\n",
      "ram:\t63 GB\n"
     ]
    }
   ],
   "source": [
    "get_system_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "388ae46c-95ed-4947-9e78-5441b0a63de9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import os\n",
    "import re\n",
    "\n",
    "import duckdb\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import polars as pl\n",
    "import seaborn as sns\n",
    "from matplotlib.collections import PolyCollection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72d1891-e144-4aec-83d8-b8e27bb9698b",
   "metadata": {},
   "source": [
    "## Problem 1. Visualizing patient trajectory\n",
    "\n",
    "Visualizing a patient’s encounters in a health care system is a common task in clinical data analysis. In this question, we will visualize a patient’s ADT (admission-discharge-transfer) history and ICU vitals in the MIMIC-IV data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15d1fd7-5922-42fd-8acc-923e8803f1d0",
   "metadata": {},
   "source": [
    "### (A). ADT history\n",
    "A patient’s ADT history records the time of admission, discharge, and transfer in the hospital. This figure shows the ADT history of the patient with subject_id `10001217` in the MIMIC-IV data. The x-axis is the calendar time, and the y-axis is the type of event (ADT, lab, procedure). The color of the line segment represents the care unit. The size of the line segment represents whether the care unit is an ICU/CCU. The crosses represent lab events, and the shape of the dots represents the type of procedure. The title of the figure shows the patient’s demographic information and the subtitle shows top 3 diagnoses. Try to create a figure similar to the below:\n",
    "\n",
    "<figure>\n",
    "  <img src=\"https://raw.githubusercontent.com/ucla-biostat-203b/2024winter/main/hw/hw3/10001217_adt.png\" style=\"width:600px\">\n",
    "</figure>\n",
    "\n",
    "\n",
    "Your figure does not need to be the same, but all the information in this figure should be reasonably arranged in your figure. Hint: consider using `dodge` keyword arguments of seaborn to do something similar to `jitter` of `ggplot2`. \n",
    "\n",
    "\n",
    "\n",
    "Hint: We need to pull information from data files `patients.csv.gz`, `admissions.csv.gz`, `transfers.csv.gz`, `labevents.csv.gz`, `procedures_icd.csv.gz`, `diagnoses_icd.csv.gz`, `d_icd_procedures.csv.gz`, and `d_icd_diagnoses.csv.gz`. For the big file `labevents.csv.gz`, use the Parquet file you generated in Homework 3. More information is available in later problems.\n",
    "\n",
    "For reproducibility, make the Parquet file available at the current working directory, for example, by a symbolic link. Make your code reproducible using relative path.\n",
    "\n",
    "Do a similar visualization for the patient `10013310`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62937236-0127-4c84-9c0c-e00485a4336e",
   "metadata": {},
   "source": [
    "### ANSWER 1A\n",
    "\n",
    "#### Function Documentation\n",
    "\n",
    "- `csvgz_to_parquet`: Converts all `csv.gz` files in a list of directories to `parquet` using the DuckDB and the os libraries. The os library is used to list all files in the directory and filters for `csv.gz` files. DuckDB is used to ingest as a table where all columns are assigned dtype `string`. The tables are then written as `parquet`.\n",
    "\n",
    "- `parquet_to_lazydict`: Creates a dictionary of `pl.LazyFrames` using the Polars and os libraries. The os library is used to list all files in the directory and filters for `parquet` files. Polars is used to ingest as a `pl.LazyFrame` by scanning all parquets in a directory and appending them to a dictionary where each key is the filename.\n",
    "\n",
    "- `lazy_to_df`: Converts `pl.LazyFrames` into a dictionary to `pl.DataFrames` that start with a prefix. The `pl.DataFrame` is a Polars DataFrame not a Pandas DataFrame (`pd.DataFrame`).\n",
    "\n",
    "- `sid_admissions`: Processes the Admissions LazyFrame by filtering rows by subject ID, selecting columns, and assigning column dtypes. The processed LazyFrame is then added to the dictionary with a new key.\n",
    "\n",
    "- `sid_patient`: Processes the Patient LazyFrame by filtering rows by subject ID, selecting columns, and assigning column dtypes. The processed LazyFrame is then added to the dictionary with a new key.\n",
    "\n",
    "- `sid_diagnosis`: Processes the Diagnosis and Diagnosis Key LazyFrames by filtering rows by subject ID, joining with the key set, and assigning column dtypes. The processed LazyFrame is then added to the dictionary with a new key.\n",
    "\n",
    "- `sid_labevents`: Processes the Lab Events LazyFrame by filtering rows by subject ID and item IDs, selecting columns, and assigning column dtypes. The processed LazyFrame is then added to the dictionary with a new key.\n",
    "\n",
    "- `sid_procedures`: Processes the Procedures and Procedures Key LazyFrames by filtering by subject ID, joining with the key set, and assigning column dtypes. The processed LazyFrame is then added to the dictionary with a new key.\n",
    "\n",
    "- `sid_transfer`: Processes the Transfers LazyFrame by filtering rows by subject ID, excluding discharge events, selecting columns, and assigning column dtypes. The processed LazyFrame is then added to the dictionary with a new key.\n",
    "\n",
    "- `sid_chartevents`: This function processes the Chartevents and Chartevents key LazyFrames by filtering rows based on a subject ID and item IDs, joining with the key set, and assigning column dtypes. The processed LazyFrame is then added to the dictionary with a new key.\n",
    "\n",
    "- `create_lazy_and_plot_df`: This function creates a dictionary of LazyFrames and a dictionary of dataframes. The lazyframe dictionary contains all datasets including plot datasets. The dataframe dictionary containes collected lazyframes needed to make plots for an subject ID. First, the lazyframe dictionary is created from all Parquet files in a directory. Then the lazyframes that will be used to make plots are prepared using the sid_{dataset}() functions which filter, select, assign types, and/or join keys. There is also an error checker for robustness that returns all of the all of the names that are required but not included as a key in lazydict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6d568fba-6f7e-4791-9f49-0b473f13a312",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def csvgz_to_parquet(dir_list: list[str]) -> None:\n",
    "    \"\"\"\n",
    "    Convert all csv.gz files in a directory list to parquet files.\n",
    "    All columns are dtype string.\n",
    "    ---\n",
    "    Args:\n",
    "        dir_list: A list of the realtive or absolute directory paths.\n",
    "    Return:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # loop through user provided list\n",
    "    for path in dir_list:\n",
    "        # Loop through all files in directory\n",
    "        for filename in os.listdir(path):\n",
    "            # Ignore dot-files\n",
    "            if filename.startswith(\".\"):\n",
    "                continue\n",
    "            # if filename ends with \".csv.gz\"\n",
    "            if filename.endswith(\".csv.gz\"):\n",
    "                # path to .csv.gz\n",
    "                file_path = os.path.join(path, filename)\n",
    "                # parquet name\n",
    "                pq_name = filename.split(\".\")[0] + \".parquet\"\n",
    "                # parquet save path\n",
    "                pq_path = os.path.join(path, pq_name)\n",
    "                print(file_path, \" to \", pq_path)  # Verbose step\n",
    "                with duckdb.connect(database=\":memory:\") as con:\n",
    "                    # Read in the compressed file from .csv.gz file path\n",
    "                    # Set All columns to type string with ALL_VARCHAR\n",
    "                    # Set ___ to null\n",
    "                    # Write table as Parquet\n",
    "                    con.execute(\n",
    "                        f\"\"\"\n",
    "                            COPY (\n",
    "                                SELECT * FROM read_csv_auto(\n",
    "                                    '{file_path}', \n",
    "                                    ALL_VARCHAR=True,\n",
    "                                    nullstr='___'\n",
    "                                )\n",
    "                            ) \n",
    "                            TO '{pq_path}' (FORMAT PARQUET);\n",
    "                        \"\"\"\n",
    "                    )\n",
    "\n",
    "\n",
    "def parquet_to_lazydict(dir_path: str) -> dict[str, pl.LazyFrame]:\n",
    "    \"\"\"\n",
    "    Read in all parquet files in a directory with Polars as LazyFrames.\n",
    "    ---\n",
    "    Args:\n",
    "        dir_path: A string of the realtive or absolute directory path.\n",
    "    Return:\n",
    "        lazy_dict: A dictionary of LazyFrames.\n",
    "    \"\"\"\n",
    "    # Initialize lazyframe dictionary\n",
    "    lazy_dict = dict()\n",
    "    # Loop through every file in directory\n",
    "    for file in os.listdir(dir_path):\n",
    "        # Select files that end with parquet\n",
    "        if file.endswith(\".parquet\"):\n",
    "            # Path to each parquet\n",
    "            name = file.split(\".\")[0]\n",
    "            file_path = os.path.join(dir_path, file)\n",
    "            # append each entry to lazy_dict\n",
    "            # key is file name and value is lazyframe\n",
    "            lazy_dict[name] = pl.scan_parquet(file_path)\n",
    "    return lazy_dict\n",
    "\n",
    "\n",
    "def lazy_to_df(lazy_dict: dict[str, pl.LazyFrame], prefix: str) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Convert pl.LazyFrames to pl.DataFrames in a dictionary where the key starts\n",
    "    with the prefix.\n",
    "    ---\n",
    "    Args:\n",
    "        lazy_dict: Dictionary of Polars LazyFrames\n",
    "        prefix: String and prefix of key in dictionary\n",
    "    Return:\n",
    "        df_dict: A dictionary of Polars DataFrames\n",
    "    \"\"\"\n",
    "    df_dict = dict()  # init dict\n",
    "    # Loop through all values in lazyframe dictionary\n",
    "    for key, value in lazy_dict.items():\n",
    "        # Filter LazyFrames by keys that start with the prefix\n",
    "        if key.startswith(prefix):\n",
    "            # Convert pl.LazyFrame to pl.DataFrame and Save to dictionary\n",
    "            df_dict[key] = value.collect()\n",
    "    return df_dict\n",
    "\n",
    "\n",
    "def sid_admissions(lazy_dict: dict[str, pl.LazyFrame], sid: str) -> dict:\n",
    "    \"\"\"\n",
    "    Filter rows, select columns, and assign dtypes to the Admissions dataset.\n",
    "    ---\n",
    "    Args:\n",
    "        lazy_dict: A dictionary of Polars LazyFrames\n",
    "        sid: A string of digits corresponding to the Subject ID.\n",
    "    Return:\n",
    "        lazy_dict: A dictionary of Polars LazyFrames and a processed plot table.\n",
    "    \"\"\"\n",
    "    lazy_dict[\"plot_admissions\"] = (\n",
    "        # Admissions Dataset\n",
    "        lazy_dict[\"admissions\"]\n",
    "        # filter by sid\n",
    "        .filter(pl.col(\"subject_id\") == sid)\n",
    "        # select columns to keep\n",
    "        .select(\n",
    "            [\n",
    "                \"subject_id\",\n",
    "                \"hadm_id\",\n",
    "                \"admittime\",\n",
    "                \"dischtime\",\n",
    "                \"deathtime\",\n",
    "                \"admission_type\",\n",
    "                \"admit_provider_id\",\n",
    "                \"admission_location\",\n",
    "                \"discharge_location\",\n",
    "                \"insurance\",\n",
    "                \"language\",\n",
    "                \"marital_status\",\n",
    "                \"race\",\n",
    "                \"edregtime\",\n",
    "                \"edouttime\",\n",
    "            ]\n",
    "        )\n",
    "        # Change column dtype\n",
    "        .cast(\n",
    "            {\n",
    "                \"subject_id\": pl.Int64,\n",
    "                \"hadm_id\": pl.Int64,\n",
    "                \"admission_type\": pl.String,\n",
    "                \"admit_provider_id\": pl.String,\n",
    "                \"admission_location\": pl.String,\n",
    "                \"discharge_location\": pl.String,\n",
    "                \"insurance\": pl.String,\n",
    "                \"language\": pl.String,\n",
    "                \"marital_status\": pl.String,\n",
    "                \"race\": pl.String,\n",
    "            }\n",
    "        )\n",
    "        # Change column dtype to Date\n",
    "        .with_columns(\n",
    "            pl.col(\"admittime\").str.to_datetime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "            pl.col(\"dischtime\").str.to_datetime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "            pl.col(\"deathtime\").str.to_datetime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "            pl.col(\"edregtime\").str.to_datetime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "            pl.col(\"edouttime\").str.to_datetime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        )\n",
    "    )\n",
    "    return lazy_dict\n",
    "\n",
    "\n",
    "def sid_patient(lazy_dict: dict[str, pl.LazyFrame], sid: str) -> dict:\n",
    "    \"\"\"\n",
    "    Filter rows, select columns, and assign dtypes to the Patient dataset.\n",
    "    ---\n",
    "    Args:\n",
    "        lazy_dict: A dictionary of Polars LazyFrames\n",
    "        sid: A string of digits corresponding to the Subject ID.\n",
    "    Return:\n",
    "        lazy_dict: A dictionary of Polars LazyFrames and a processed plot table.\n",
    "    \"\"\"\n",
    "    lazy_dict[\"plot_patient\"] = (\n",
    "        # Patient Info Dataset\n",
    "        lazy_dict[\"patients\"]\n",
    "        # Filter by sid\n",
    "        .filter(pl.col(\"subject_id\") == sid)\n",
    "        # Change column dtype\n",
    "        .cast(\n",
    "            {\n",
    "                \"subject_id\": pl.Int64,\n",
    "                \"anchor_age\": pl.Int64,\n",
    "                \"anchor_year\": pl.Int64,\n",
    "                \"dod\": pl.Date,\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "    return lazy_dict\n",
    "\n",
    "\n",
    "def sid_diagnosis(lazy_dict: dict[str, pl.LazyFrame], sid: str) -> dict:\n",
    "    \"\"\"\n",
    "    Filter rows, select columns, join item key, and assign dtypes\n",
    "    to the Diagnosis dataset.\n",
    "    ---\n",
    "    Args:\n",
    "        lazy_dict: A dictionary of Polars LazyFrames\n",
    "        sid: A string of digits corresponding to the Subject ID.\n",
    "    Return:\n",
    "        lazy_dict: A dictionary of Polars LazyFrames and a processed plot table.\n",
    "    \"\"\"\n",
    "    lazy_dict[\"plot_diagnosis\"] = (\n",
    "        # diagnosis dataset\n",
    "        lazy_dict[\"diagnoses_icd\"]\n",
    "        # Filter by sid\n",
    "        .filter(pl.col(\"subject_id\") == sid)\n",
    "        # Change column dtype\n",
    "        .cast({\"subject_id\": pl.Int64, \"hadm_id\": pl.Int64, \"seq_num\": pl.Int64})\n",
    "        # Join diagnosis key\n",
    "        .join(lazy_dict[\"d_icd_diagnoses\"], on=\"icd_code\", how=\"left\")\n",
    "        # Convert short title from long title\n",
    "        .with_columns(\n",
    "            pl.col(\"long_title\").str.extract(r\"^[^,]*\", 0).alias(\"short_title\")\n",
    "        )\n",
    "    )\n",
    "    return lazy_dict\n",
    "\n",
    "\n",
    "def sid_labevents(lazy_dict: dict[str, pl.LazyFrame], sid: str) -> dict:\n",
    "    \"\"\"\n",
    "    Filter rows, select columns, and assign dtypes to the Lab Events dataset.\n",
    "    ---\n",
    "    Args:\n",
    "        lazy_dict: A dictionary of Polars LazyFrames\n",
    "        sid: A string of digits corresponding to the Subject ID.\n",
    "    Return:\n",
    "        lazy_dict: A dictionary of Polars LazyFrames and a processed plot table.\n",
    "    \"\"\"\n",
    "    # list of itemids to filter by\n",
    "    lab_itemid = [\n",
    "        \"50912\",\n",
    "        \"50971\",\n",
    "        \"50983\",\n",
    "        \"50902\",\n",
    "        \"50882\",\n",
    "        \"51221\",\n",
    "        \"51301\",\n",
    "        \"50931\",\n",
    "    ]\n",
    "\n",
    "    lazy_dict[\"d_labitems\"] = (\n",
    "        lazy_dict[\"d_labitems\"]\n",
    "        .select([\"itemid\", \"label\"])\n",
    "        .filter(pl.col(\"itemid\").is_in(lab_itemid))\n",
    "        .cast({\"itemid\": pl.Int64})\n",
    "    )\n",
    "\n",
    "    lazy_dict[\"plot_lab\"] = (\n",
    "        # Labevents dataset\n",
    "        lazy_dict[\"labevents\"]\n",
    "        # select columns to keep\n",
    "        .select(\n",
    "            [\n",
    "                \"labevent_id\",\n",
    "                \"subject_id\",\n",
    "                \"hadm_id\",\n",
    "                \"specimen_id\",\n",
    "                \"itemid\",\n",
    "                \"order_provider_id\",\n",
    "                \"charttime\",\n",
    "                \"storetime\",\n",
    "                \"valuenum\",\n",
    "                \"valueuom\",\n",
    "            ]\n",
    "        )\n",
    "        # Filter by sid and itemid\n",
    "        .filter(pl.col(\"subject_id\") == sid, pl.col(\"itemid\").is_in(lab_itemid))\n",
    "        # Change column dtype\n",
    "        .cast(\n",
    "            {\n",
    "                \"labevent_id\": pl.Int64,\n",
    "                \"subject_id\": pl.Int64,\n",
    "                \"hadm_id\": pl.Int64,\n",
    "                \"specimen_id\": pl.Int64,\n",
    "                \"itemid\": pl.Int64,\n",
    "                \"valuenum\": pl.Float64,\n",
    "            }\n",
    "        )\n",
    "        # Convert dtype to datetime\n",
    "        .with_columns(\n",
    "            pl.col(\"charttime\").str.to_datetime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "            pl.col(\"storetime\").str.to_datetime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        ).join(lazy_dict[\"d_labitems\"], on=\"itemid\", how=\"left\")\n",
    "    )\n",
    "    return lazy_dict\n",
    "\n",
    "\n",
    "def sid_procedures(lazy_dict: dict[str, pl.LazyFrame], sid: str) -> dict:\n",
    "    \"\"\"\n",
    "    Filter rows, select columns, join item key, and assign dtypes\n",
    "    to the Procedures dataset.\n",
    "    ---\n",
    "    Args:\n",
    "        lazy_dict: A dictionary of Polars LazyFrames\n",
    "        sid: A string of digits corresponding to the Subject ID.\n",
    "    Return:\n",
    "        lazy_dict: A dictionary of Polars LazyFrames and a processed plot table.\n",
    "    \"\"\"\n",
    "    # preparing procedure key\n",
    "    lazy_dict[\"d_icd_procedures\"] = lazy_dict[\"d_icd_procedures\"].select(\n",
    "        [\"icd_code\", \"long_title\"]\n",
    "    )\n",
    "\n",
    "    lazy_dict[\"plot_procedures\"] = (\n",
    "        # procedure dataset\n",
    "        lazy_dict[\"procedures_icd\"]\n",
    "        # select columns to keep\n",
    "        .select([\"subject_id\", \"hadm_id\", \"seq_num\", \"chartdate\", \"icd_code\"])\n",
    "        # Filter by sid\n",
    "        .filter(pl.col(\"subject_id\") == sid)\n",
    "        # Change column dtype\n",
    "        .cast(\n",
    "            {\n",
    "                \"subject_id\": pl.Int64,\n",
    "                \"hadm_id\": pl.Int64,\n",
    "                \"seq_num\": pl.Int64,\n",
    "                \"icd_code\": pl.String,\n",
    "                \"chartdate\": pl.Date,\n",
    "            }\n",
    "        )\n",
    "        # Join procedures key\n",
    "        .join(lazy_dict[\"d_icd_procedures\"], on=\"icd_code\", how=\"left\")\n",
    "        # convert long title to short title\n",
    "        .with_columns(\n",
    "            pl.col(\"long_title\").str.extract(r\"^[^,]*\", 0).alias(\"short_title\")\n",
    "        )\n",
    "    )\n",
    "    return lazy_dict\n",
    "\n",
    "\n",
    "def sid_transfer(lazy_dict: dict[str, pl.LazyFrame], sid: str) -> dict:\n",
    "    \"\"\"\n",
    "    Filter rows, select columns, and assign dtypes to the Transfers dataset.\n",
    "    ---\n",
    "    Args:\n",
    "        lazy_dict: A dictionary of Polars LazyFrames\n",
    "        sid: A string of digits corresponding to the Subject ID.\n",
    "    Return:\n",
    "        lazy_dict: A dictionary of Polars LazyFrames and a processed plot table.\n",
    "    \"\"\"\n",
    "    lazy_dict[\"plot_transfer\"] = (\n",
    "        # transfers dataset\n",
    "        lazy_dict[\"transfers\"]\n",
    "        # filter by sid\n",
    "        .filter(pl.col(\"subject_id\") == sid, pl.col(\"eventtype\") != \"discharge\")\n",
    "        # Change column dtype\n",
    "        .cast(\n",
    "            {\n",
    "                \"subject_id\": pl.Int64,\n",
    "                \"hadm_id\": pl.Int64,\n",
    "                \"transfer_id\": pl.Int64,\n",
    "                \"eventtype\": pl.String,\n",
    "                \"careunit\": pl.String,\n",
    "            }\n",
    "        ).with_columns(\n",
    "            # Convert string columns to date\n",
    "            pl.col(\"intime\").str.slice(0, 10).str.to_date(),\n",
    "            pl.col(\"outtime\").str.slice(0, 10).str.to_date(),\n",
    "            # Add a bivariate critical care column if in ICU or CCU\n",
    "            (\n",
    "                pl.when(pl.col(\"careunit\").str.contains(\"ICU|CCU\"))\n",
    "                .then(pl.lit(\"Critical_Care\"))\n",
    "                .otherwise(pl.lit(\"\"))\n",
    "                .alias(\"Critical_Care\")\n",
    "            ),\n",
    "            # Add a column ADT with values of ADT\n",
    "            (\n",
    "                pl.when(pl.col(\"careunit\").is_not_null())\n",
    "                .then(pl.lit(\"ADT\"))\n",
    "                .otherwise(pl.lit(\"\"))\n",
    "                .alias(\"ADT\")\n",
    "            ),\n",
    "        )\n",
    "    )\n",
    "    return lazy_dict\n",
    "\n",
    "\n",
    "def sid_chartevents(lazy_dict: dict[str, pl.LazyFrame], sid: str) -> dict:\n",
    "    \"\"\"\n",
    "    Filter rows, select columns, join item key, and assign dtypes\n",
    "    to the Chartevents dataset.\n",
    "    ---\n",
    "    Args:\n",
    "        lazy_dict: A dictionary of Polars LazyFrames\n",
    "        sid: A string of digits corresponding to the Subject ID.\n",
    "    Return:\n",
    "        lazy_dict: A dictionary of Polars LazyFrames and a processed plot table.\n",
    "    \"\"\"\n",
    "    # Chartevents item key\n",
    "    lazy_dict[\"d_items\"] = (\n",
    "        lazy_dict[\"d_items\"]\n",
    "        # select columns to keep\n",
    "        .select([\"itemid\", \"label\", \"abbreviation\", \"unitname\"])\n",
    "        # convert dtype of columns\n",
    "        .cast(\n",
    "            {\n",
    "                \"itemid\": pl.Int64,\n",
    "                \"label\": pl.String,\n",
    "                \"abbreviation\": pl.String,\n",
    "                \"unitname\": pl.String,\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Patient chartevents\n",
    "    lazy_dict[\"plot_chartevents\"] = (\n",
    "        # Chartevents dataset\n",
    "        lazy_dict[\"chartevents\"]\n",
    "        # Filter by sid and itemid\n",
    "        .filter(\n",
    "            pl.col(\"subject_id\") == sid,\n",
    "            pl.col(\"itemid\").is_in([\"220045\", \"220181\", \"220179\", \"223761\", \"220210\"]),\n",
    "        )\n",
    "        # Select columns to keep\n",
    "        .select(\n",
    "            [\n",
    "                \"subject_id\",\n",
    "                \"hadm_id\",\n",
    "                \"stay_id\",\n",
    "                \"charttime\",\n",
    "                \"storetime\",\n",
    "                \"itemid\",\n",
    "                \"valuenum\",\n",
    "                \"valueuom\",\n",
    "            ]\n",
    "        )\n",
    "        # Change column dtype\n",
    "        .cast(\n",
    "            {\n",
    "                \"subject_id\": pl.Int64,\n",
    "                \"hadm_id\": pl.Int64,\n",
    "                \"stay_id\": pl.Int64,\n",
    "                \"itemid\": pl.Int64,\n",
    "                \"valuenum\": pl.Float64,\n",
    "                \"valueuom\": pl.String,\n",
    "            }\n",
    "        )\n",
    "        # Convert columns to datetime\n",
    "        .with_columns(\n",
    "            pl.col(\"charttime\").str.to_datetime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "            pl.col(\"storetime\").str.to_datetime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        )\n",
    "        # join item key\n",
    "        .join(lazy_dict[\"d_items\"], on=\"itemid\", how=\"left\")\n",
    "    )\n",
    "    return lazy_dict\n",
    "\n",
    "\n",
    "def create_lazy_and_plot_df(sid: int, dir_path: str) -> tuple:\n",
    "    \"\"\"\n",
    "    Create a dictionary with of LazyFrames of all parquet files in a directory.\n",
    "    Format, filter, and prepare data for use in plots.\n",
    "    Convert plot lazyframes to dataframes.\n",
    "    ---\n",
    "    Args:\n",
    "        sid: An integer representing a subject ID.\n",
    "    Returns:\n",
    "        lazy_dict: A dictionary of LazyFrames\n",
    "        df_dict: A dictionary of DataFrames\n",
    "    \"\"\"\n",
    "    # Create a dictionary with of LazyFrames of all parquet files in a directory\n",
    "    lazy_dict = parquet_to_lazydict(dir_path)\n",
    "    # Convert subject ID to string because columns in parquet are dtype string\n",
    "    sid = str(sid)\n",
    "    # list of names converted to lazyframe from directory.\n",
    "    lazy_names = [key for key in lazy_dict]\n",
    "    # name requirements.\n",
    "    req_names = [\n",
    "        \"patients\",\n",
    "        \"admissions\",\n",
    "        \"transfers\",\n",
    "        \"procedures_icd\",\n",
    "        \"d_icd_procedures\",\n",
    "        \"diagnoses_icd\",\n",
    "        \"d_icd_diagnoses\",\n",
    "        \"labevents\",\n",
    "        \"d_labitems\",\n",
    "        \"chartevents\",\n",
    "        \"d_items\",\n",
    "    ]\n",
    "    # list of all required names not in lazy_names\n",
    "    missing_names = [n for n in req_names if n not in lazy_names]\n",
    "    # Error Catch before performing filtering fucntions\n",
    "    if missing_names:\n",
    "        raise KeyError(f'Names not found: {\", \".join(missing_names)}')\n",
    "    # Fucntions to prepare datasets for graphing\n",
    "    sid_patient(lazy_dict, sid)\n",
    "    sid_admissions(lazy_dict, sid)\n",
    "    sid_transfer(lazy_dict, sid)\n",
    "    sid_procedures(lazy_dict, sid)\n",
    "    sid_diagnosis(lazy_dict, sid)\n",
    "    sid_labevents(lazy_dict, sid)\n",
    "    sid_chartevents(lazy_dict, sid)\n",
    "    # convert plot lazyframe to dataframe\n",
    "    df_dict = lazy_to_df(lazy_dict, \"plot\")\n",
    "    # return both lazyframe and plot dataframes\n",
    "    return lazy_dict, df_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2145d9-724b-470b-be26-52b58132b37d",
   "metadata": {},
   "source": [
    "#### `.csv.gz` to `parquet` Documentation\n",
    "\n",
    "- All `.csv.gz` files that were converted to `parquet` using `csvgz_to_parquet`\n",
    "- DuckDB was faster than Polars. DuckDB took 4 minutes to convert `.csv.gz` files that were converted to `parquet` and Polars took 6 minutes to convert the same `.csv.gz` files that were converted to `parquet`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "27923c93-ff3e-45da-bd9c-1b44446d1cfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./mimic/hosp/poe.csv.gz  to  ./mimic/hosp/poe.parquet\n",
      "./mimic/hosp/d_hcpcs.csv.gz  to  ./mimic/hosp/d_hcpcs.parquet\n",
      "./mimic/hosp/poe_detail.csv.gz  to  ./mimic/hosp/poe_detail.parquet\n",
      "./mimic/hosp/patients.csv.gz  to  ./mimic/hosp/patients.parquet\n",
      "./mimic/hosp/diagnoses_icd.csv.gz  to  ./mimic/hosp/diagnoses_icd.parquet\n",
      "./mimic/hosp/emar_detail.csv.gz  to  ./mimic/hosp/emar_detail.parquet\n",
      "./mimic/hosp/provider.csv.gz  to  ./mimic/hosp/provider.parquet\n",
      "./mimic/hosp/prescriptions.csv.gz  to  ./mimic/hosp/prescriptions.parquet\n",
      "./mimic/hosp/drgcodes.csv.gz  to  ./mimic/hosp/drgcodes.parquet\n",
      "./mimic/hosp/d_icd_diagnoses.csv.gz  to  ./mimic/hosp/d_icd_diagnoses.parquet\n",
      "./mimic/hosp/d_labitems.csv.gz  to  ./mimic/hosp/d_labitems.parquet\n",
      "./mimic/hosp/transfers.csv.gz  to  ./mimic/hosp/transfers.parquet\n",
      "./mimic/hosp/admissions.csv.gz  to  ./mimic/hosp/admissions.parquet\n",
      "./mimic/hosp/labevents.csv.gz  to  ./mimic/hosp/labevents.parquet\n",
      "./mimic/hosp/pharmacy.csv.gz  to  ./mimic/hosp/pharmacy.parquet\n",
      "./mimic/hosp/procedures_icd.csv.gz  to  ./mimic/hosp/procedures_icd.parquet\n",
      "./mimic/hosp/hcpcsevents.csv.gz  to  ./mimic/hosp/hcpcsevents.parquet\n",
      "./mimic/hosp/services.csv.gz  to  ./mimic/hosp/services.parquet\n",
      "./mimic/hosp/d_icd_procedures.csv.gz  to  ./mimic/hosp/d_icd_procedures.parquet\n",
      "./mimic/hosp/omr.csv.gz  to  ./mimic/hosp/omr.parquet\n",
      "./mimic/hosp/emar.csv.gz  to  ./mimic/hosp/emar.parquet\n",
      "./mimic/hosp/microbiologyevents.csv.gz  to  ./mimic/hosp/microbiologyevents.parquet\n",
      "./mimic/icu/datetimeevents.csv.gz  to  ./mimic/icu/datetimeevents.parquet\n",
      "./mimic/icu/caregiver.csv.gz  to  ./mimic/icu/caregiver.parquet\n",
      "./mimic/icu/ingredientevents.csv.gz  to  ./mimic/icu/ingredientevents.parquet\n",
      "./mimic/icu/inputevents.csv.gz  to  ./mimic/icu/inputevents.parquet\n",
      "./mimic/icu/procedureevents.csv.gz  to  ./mimic/icu/procedureevents.parquet\n",
      "./mimic/icu/d_items.csv.gz  to  ./mimic/icu/d_items.parquet\n",
      "./mimic/icu/chartevents.csv.gz  to  ./mimic/icu/chartevents.parquet\n",
      "./mimic/icu/icustays.csv.gz  to  ./mimic/icu/icustays.parquet\n",
      "./mimic/icu/outputevents.csv.gz  to  ./mimic/icu/outputevents.parquet\n",
      "CPU times: user 22min 7s, sys: 2min 11s, total: 24min 18s\n",
      "Wall time: 4min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "csvgz_paths = [\"./mimic/hosp\", \"./mimic/icu\"]\n",
    "csvgz_to_parquet(csvgz_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ceadaa-0d02-4c0d-bb5f-3e6c643bc1f1",
   "metadata": {},
   "source": [
    "#### Symbolic Link Documentation\n",
    "- Created Symbolic links from mimic data directories to the working directory. Only performed for the files that were needed to make the plot. Change the Directories to match your system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3944fffa-9723-4b41-80c7-d535d972c1f7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 41034731      0 lrwxrwxrwx   1 wtmartinez wtmartinez       30 May 22 10:27 ./transfers.parquet -> ./mimic/hosp/transfers.parquet\n",
      " 41034735      0 lrwxrwxrwx   1 wtmartinez wtmartinez       34 May 22 10:27 ./diagnoses_icd.parquet -> ./mimic/hosp/diagnoses_icd.parquet\n",
      " 41034852      0 lrwxrwxrwx   1 wtmartinez wtmartinez       28 May 22 10:27 ./mimic -> /media/wtmartinez/Data/mimic\n",
      " 41034736      0 lrwxrwxrwx   1 wtmartinez wtmartinez       36 May 20 02:29 ./d_icd_diagnoses.parquet -> ./mimic/hosp/d_icd_diagnoses.parquet\n",
      " 41034850      0 lrwxrwxrwx   1 wtmartinez wtmartinez       31 May 22 10:27 ./admissions.parquet -> ./mimic/hosp/admissions.parquet\n",
      " 41034857      0 lrwxrwxrwx   1 wtmartinez wtmartinez       36 May 22 10:27 ./d_icmd_diagnoses.parquet -> ./mimic/hosp/d_icd_diagnoses.parquet\n",
      " 41034737      0 lrwxrwxrwx   1 wtmartinez wtmartinez       31 May 22 10:27 ./chartevents.parquet -> ./mimic/icu/chartevents.parquet\n",
      " 41034717      0 lrwxrwxrwx   1 wtmartinez wtmartinez       27 May 22 10:27 ./d_items.parquet -> ./mimic/icu/d_items.parquet\n",
      " 41034732      0 lrwxrwxrwx   1 wtmartinez wtmartinez       35 May 22 10:27 ./procedures_icd.parquet -> ./mimic/hosp/procedures_icd.parquet\n",
      " 41034847      0 lrwxrwxrwx   1 wtmartinez wtmartinez       31 May 22 10:27 ./d_labitems.parquet -> ./mimic/hosp/d_labitems.parquet\n",
      " 41034848      0 lrwxrwxrwx   1 wtmartinez wtmartinez       29 May 22 10:27 ./patients.parquet -> ./mimic/hosp/patients.parquet\n",
      " 41034733      0 lrwxrwxrwx   1 wtmartinez wtmartinez       30 May 22 10:27 ./labevents.parquet -> ./mimic/hosp/labevents.parquet\n",
      " 41034856      0 lrwxrwxrwx   1 wtmartinez wtmartinez       37 May 22 10:27 ./d_icd_procedures.parquet -> ./mimic/hosp/d_icd_procedures.parquet\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# Modify bash code to match directories.\n",
    "ln -sf /media/wtmartinez/Data/mimic ./\n",
    "ln -sf ./mimic/hosp/patients.parquet ./patients.parquet\n",
    "ln -sf ./mimic/hosp/admissions.parquet ./admissions.parquet\n",
    "ln -sf ./mimic/hosp/transfers.parquet ./transfers.parquet\n",
    "ln -sf ./mimic/hosp/labevents.parquet ./labevents.parquet\n",
    "ln -sf ./mimic/hosp/procedures_icd.parquet ./procedures_icd.parquet\n",
    "ln -sf ./mimic/hosp/diagnoses_icd.parquet ./diagnoses_icd.parquet\n",
    "ln -sf ./mimic/hosp/d_icd_procedures.parquet ./d_icd_procedures.parquet\n",
    "ln -sf ./mimic/hosp/d_icd_diagnoses.parquet ./d_icmd_diagnoses.parquet\n",
    "ln -sf ./mimic/hosp/d_labitems.parquet ./d_labitems.parquet\n",
    "ln -sf ./mimic/icu/chartevents.parquet ./chartevents.parquet\n",
    "ln -sf ./mimic/icu/d_items.parquet ./d_items.parquet\n",
    "find . -type l -ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04eb4d09-9fc0-4544-94c5-f10507eb04da",
   "metadata": {},
   "source": [
    "#### Reading and Preparing Data Documentation\n",
    "- The `create_lazy_and_plot_df` function was used to make a dictionary of lazyframes of all datasets and a dictionary of dataframes of processed plotting datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8fad206f-9e5e-42ae-a97e-5a337b0e9b0f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 244 ms, sys: 152 ms, total: 396 ms\n",
      "Wall time: 365 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lazy_dict, df_dict = create_lazy_and_plot_df(10013310, \"./\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109b92d5-69df-4799-8058-d32a379649ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Plotting Documentation\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2924471d-f9c2-4acf-a2c0-4ced40946db1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = [\n",
    "    (dt.datetime(2018, 7, 17, 0, 15), dt.datetime(2018, 7, 17, 0, 30), \"sleep\"),\n",
    "    (dt.datetime(2018, 7, 17, 0, 30), dt.datetime(2018, 7, 17, 0, 45), \"eat\"),\n",
    "    (dt.datetime(2018, 7, 17, 0, 45), dt.datetime(2018, 7, 17, 1, 0), \"work\"),\n",
    "    (dt.datetime(2018, 7, 17, 1, 0), dt.datetime(2018, 7, 17, 1, 30), \"sleep\"),\n",
    "    (dt.datetime(2018, 7, 17, 1, 15), dt.datetime(2018, 7, 17, 1, 30), \"eat\"),\n",
    "    (dt.datetime(2018, 7, 17, 1, 30), dt.datetime(2018, 7, 17, 1, 45), \"work\"),\n",
    "]\n",
    "\n",
    "cats = {\"sleep\": 1, \"eat\": 2, \"work\": 3}\n",
    "colormapping = {\"sleep\": \"C0\", \"eat\": \"C1\", \"work\": \"C2\"}\n",
    "\n",
    "verts = []\n",
    "colors = []\n",
    "for d in data:\n",
    "    v = [\n",
    "        (mdates.date2num(d[0]), cats[d[2]] - 0.4),\n",
    "        (mdates.date2num(d[0]), cats[d[2]] + 0.4),\n",
    "        (mdates.date2num(d[1]), cats[d[2]] + 0.4),\n",
    "        (mdates.date2num(d[1]), cats[d[2]] - 0.4),\n",
    "        (mdates.date2num(d[0]), cats[d[2]] - 0.4),\n",
    "    ]\n",
    "    verts.append(v)\n",
    "    colors.append(colormapping[d[2]])\n",
    "\n",
    "bars = PolyCollection(verts, facecolors=colors)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.add_collection(bars)\n",
    "ax.autoscale()\n",
    "loc = mdates.MinuteLocator(byminute=[0, 15, 30, 45])\n",
    "ax.xaxis.set_major_locator(loc)\n",
    "ax.xaxis.set_major_formatter(mdates.AutoDateFormatter(loc))\n",
    "\n",
    "ax.set_yticks([1, 2, 3])\n",
    "ax.set_yticklabels([\"sleep\", \"eat\", \"work\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517cb7da-e92b-4383-a6ca-b763dc20d355",
   "metadata": {},
   "source": [
    "### (B). ICU stays\n",
    "ICU stays are a subset of ADT history. This figure shows the vitals of the patient `10001217` during ICU stays. The x-axis is the calendar time, and the y-axis is the value of the vital. The color of the line represents the type of vital. The facet grid shows the abbreviation of the vital and the stay ID. These vitals are: heart rate (220045), systolic non-invasive blood pressure (220179), diastolic non-invasive blood pressure (220180), body temperature in Fahrenheit (223761), and respiratory rate (220210). Try to create a figure similar to below:\n",
    "\n",
    "\n",
    "<figure>\n",
    "  <img src=\"https://raw.githubusercontent.com/ucla-biostat-203b/2024winter/main/hw/hw3/10001217_icu.png\" style=\"width:600px\">\n",
    "</figure>\n",
    "\n",
    "Repeat a similar visualization for the patient `10013310`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b473681e-10e0-41dc-bef2-c4d63478df89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6244ac93-d851-494a-9e79-3045a9d0f3c0",
   "metadata": {},
   "source": [
    "## Problem 2. ICU stays"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3856d9-9464-434d-bcb8-73d773a75845",
   "metadata": {},
   "source": [
    "`icustays.csv.gz` (https://mimic.mit.edu/docs/iv/modules/icu/icustays/) contains data about Intensive Care Units (ICU) stays. The first 10 lines are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5df16e2-3f44-4a3a-ab16-02098b8c6004",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: line 1: /home/wtmartinez/mimic/icu/icustays.csv.gz: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!zcat < ~/mimic/icu/icustays.csv.gz | head"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db68612f-6755-4916-8485-d72a0ad5e4c0",
   "metadata": {},
   "source": [
    "### (A). Ingestion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06854a3-b121-4f8b-92f5-b6bd4d761658",
   "metadata": {},
   "source": [
    "Import `icustays.csv.gz` as a DataFrame `icustays_df`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5678552-a26d-4296-bcf6-1a78bb60da36",
   "metadata": {},
   "source": [
    "### (B). Summary and visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67e4ae0-cf6f-4dd8-856f-bad0f3a33bf3",
   "metadata": {},
   "source": [
    "How many unique `subject_id`? Can a `subject_id` have multiple ICU stays? Summarize the number of ICU stays per `subject_id` by graphs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50d36ae-5bfc-433f-ad41-0a1d87925d2d",
   "metadata": {},
   "source": [
    "## Problem 3. `admissions` data\n",
    "\n",
    "Information of the patients admitted into hospital is available in `admissions.csv.gz`. See https://mimic.mit.edu/docs/iv/modules/hosp/admissions/ for details of each field in this file. The first 10 lines are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31d15378-1916-437b-8296-6b10f7457225",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: line 1: /home/wtmartinez/mimic/hosp/admissions.csv.gz: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!zcat < ~/mimic/hosp/admissions.csv.gz | head"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe4fa89-0aa6-4d6b-97b8-c63e3c7af0a3",
   "metadata": {},
   "source": [
    "### (A). Ingestion\n",
    "Import `admissions.csv.gz` as a data frame `admissions_df`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f912096-cebd-43dc-9b22-b2da2823c895",
   "metadata": {},
   "source": [
    "### (B). Summary and visualization\n",
    "\n",
    "Summarize the following information by graphics and explain any patterns you see.\n",
    "\n",
    "- number of admissions per patient\n",
    "- admission hour of day (anything unusual?)\n",
    "- admission minute (anything unusual?)\n",
    "- length of hospital stay (from admission to discharge) (anything unusual?)\n",
    "\n",
    "According to the MIMIC-IV documentation:\n",
    "\n",
    "> All dates in the database have been shifted to protect patient confidentiality. Dates will be internally consistent for the same patient, but randomly distributed in the future. Dates of birth which occur in the present time are not true dates of birth. Furthermore, dates of birth which occur before the year 1900 occur if the patient is older than 89. In these cases, the patient’s age at their first admission has been fixed to 300."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eecce5d-8577-43c9-852b-95c4599ec052",
   "metadata": {},
   "source": [
    "## Problem 4. `patients` data\n",
    "Patient information is available in `patients.csv.gz`. See https://mimic.mit.edu/docs/iv/modules/hosp/patients/ for details of each field in this file. The first 10 lines are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "83a0de99-57ce-43a5-934f-8c15a75ec7b2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: line 1: /home/wtmartinez/mimic/hosp/patients.csv.gz: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!zcat < ~/mimic/hosp/patients.csv.gz | head"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba0e71a-b864-48d2-a261-5c48518e4dbf",
   "metadata": {},
   "source": [
    "### (A). Ingestion\n",
    "Import `patients.csv.gz` (https://mimic.mit.edu/docs/iv/modules/hosp/patients/) as a data frame `patients_df`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1be5f75-c91c-451a-b95d-c30cd55d23a6",
   "metadata": {},
   "source": [
    "### (B). Summary and visaulization\n",
    "Summarize variables `gender` and `anchor_age` by graphics, and explain any patterns you see."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6be0e0-7535-4bea-8405-d75fd959eba9",
   "metadata": {},
   "source": [
    "## Problem 5. Lab results\n",
    "labevents.csv.gz (https://mimic.mit.edu/docs/iv/modules/hosp/labevents/) contains all laboratory measurements for patients. The first 10 lines are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39efa5f4-d11a-4ec2-bcd6-67a547058ce5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: line 1: /home/wtmartinez/mimic/hosp/labevents.csv.gz: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!zcat < ~/mimic/hosp/labevents.csv.gz | head"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2541cd27-c4ad-4112-ad9d-d36d9522f9fc",
   "metadata": {},
   "source": [
    "`d_labitems.csv.gz` (https://mimic.mit.edu/docs/iv/modules/hosp/d_labitems/) is the dictionary of lab measurements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a2c3a28-f1f0-4fe1-b7e4-2dc41664d7f3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: line 1: /home/wtmartinez/mimic/hosp/d_labitems.csv.gz: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!zcat < ~/mimic/hosp/d_labitems.csv.gz | head"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2313a8-3b0c-4378-9dec-14e5bf3d7ae0",
   "metadata": {},
   "source": [
    "We are interested in the lab measurements of creatinine (50912), potassium (50971), sodium (50983), chloride (50902), bicarbonate (50882), hematocrit (51221), white blood cell count (51301), and glucose (50931). Retrieve a subset of `labevents.csv.gz` that only containing these items for the patients in `icustays_df`. Further restrict to the last available measurement (by `storetime`) before the ICU stay. The final `labevents_df` should have one row per ICU stay and columns for each lab measurement.\n",
    "(ten columns with column names `subject_id`, `stay_id`, `Bicarbonate`, `Chloride`, ...)\n",
    "\n",
    "\n",
    "_Hint_: Use the Parquet format you generated in Homework 3. For reproducibility, make `labevents.parquet` file available at the current working directory, for example, by a symbolic link."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53202d36-290c-4dc3-8777-2e087abedb09",
   "metadata": {},
   "source": [
    "## Problem 6. Vitals from charted events"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f474a7-1302-4e42-bda0-8026295292f3",
   "metadata": {},
   "source": [
    "`chartevents.csv.gz` (https://mimic.mit.edu/docs/iv/modules/icu/chartevents/) contains all the charted data available for a patient. During their ICU stay, the primary repository of a patient’s information is their electronic chart. The `itemid` variable indicates a single measurement type in the database. The `value` variable is the value measured for `itemid`. The first 10 lines of `chartevents.csv.gz` are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e600de5f-b587-4564-8e8f-7a3db2bfb3e2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: line 1: /home/wtmartinez/mimic/icu/chartevents.csv.gz: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!zcat < ~/mimic/icu/chartevents.csv.gz | head"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665fda77-fbe0-412a-9478-35b55d0ad805",
   "metadata": {},
   "source": [
    "`d_items.csv.gz` (https://mimic.mit.edu/docs/iv/modules/icu/d_items/) is the dictionary for the itemid in `chartevents.csv.gz`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "193edb61-8af6-4264-a40a-366083b9967f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: line 1: /home/wtmartinez/mimic/icu/d_items.csv.gz: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!zcat < ~/mimic/icu/d_items.csv.gz | head"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2430ade5-d330-4080-aa2d-3ea4e9d28fea",
   "metadata": {},
   "source": [
    "We are interested in the vitals for ICU patients: heart rate (220045), systolic non-invasive blood pressure (220179), diastolic non-invasive blood pressure (220180), body temperature in Fahrenheit (223761), and respiratory rate (220210). Retrieve a subset of `chartevents.csv.gz` only containing these items for the patients in `icustays_tble`. Further restrict to the first vital measurement within the ICU stay. The final `chartevents_tble` should have one row per ICU stay and columns for each vital measurement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8876b03-ec22-4806-9be6-7aec5c0a3afc",
   "metadata": {},
   "source": [
    "Hint: Use the Parquet format you generated in Homework 3. For reproducibility, make `chartevents.parquet` file available at the current working directory, for example, by a symbolic link."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d26962-f9e4-4b9d-a783-c69d4ce4835c",
   "metadata": {},
   "source": [
    "## Problem 7. Putting things together\n",
    "Let us create a data frame `mimic_icu_cohort` for all ICU stays, where rows are all ICU stays of adults (age at `intime` >= 18) and columns contain at least following variables\n",
    "\n",
    "- all variables in `icustays_tble`\n",
    "- all variables in `admissions_tble`\n",
    "- all variables in `patients_tble`\n",
    "- the last lab measurements before the ICU stay in `labevents_tble`\n",
    "- the first vital measurements during the ICU stay in `chartevents_tble`\n",
    "- The final `mimic_icu_cohort` should have one row per ICU stay and columns for each variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57d3827-ec21-4cb1-9f22-795d6aa7f98c",
   "metadata": {},
   "source": [
    "## Problem 8. Exploratory data analysis (EDA)\n",
    "Summarize the following information about the ICU stay cohort `mimic_icu_cohort` using appropriate method:\n",
    "\n",
    "- Length of ICU stay `los` vs demographic variables (race, insurance, marital_status, gender, age at intime)\n",
    "\n",
    "- Length of ICU stay `los` vs the last available lab measurements before ICU stay\n",
    "\n",
    "- Length of ICU stay `los` vs the first vital measurements within the ICU stay\n",
    "\n",
    "- Length of ICU stay `los` vs first ICU unit\n",
    "\n",
    "At least two plots should be created, with at least one them including multiple facets using an appropriate keyword argument. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f103c71-e90d-47f0-9ad9-a6b1de96953b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "203C",
   "language": "python",
   "name": "203c"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "toc-autonumbering": false,
  "toc-showcode": true,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
